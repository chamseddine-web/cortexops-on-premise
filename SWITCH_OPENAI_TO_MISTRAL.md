# üîÑ Guide : Remplacer OpenAI par Mistral AI

Ce guide vous explique comment d√©sactiver OpenAI et utiliser exclusivement Mistral AI dans CortexOps.

---

## üìã Table des mati√®res

1. [Pourquoi remplacer OpenAI par Mistral ?](#pourquoi-remplacer-openai-par-mistral)
2. [Configuration rapide (3 √©tapes)](#configuration-rapide-3-√©tapes)
3. [D√©sactiver compl√®tement OpenAI](#d√©sactiver-compl√®tement-openai)
4. [V√©rification et tests](#v√©rification-et-tests)
5. [Comparaison des co√ªts](#comparaison-des-co√ªts)
6. [Retour en arri√®re](#retour-en-arri√®re)

---

## üéØ Pourquoi remplacer OpenAI par Mistral ?

### Avantages de Mistral AI

| Crit√®re | Mistral AI | OpenAI |
|---------|-----------|--------|
| **Co√ªt** | 0,15‚Ç¨ - 2‚Ç¨ / 1M tokens | 0,50‚Ç¨ - 30‚Ç¨ / 1M tokens |
| **Conformit√©** | RGPD europ√©en | US Cloud Act |
| **Latence** | ~200-500ms | ~500-1000ms |
| **Qualit√©** | Excellente | Premium |
| **Donn√©es** | Europe (France) | USA |
| **Disponibilit√©** | 99,9% | 99,9% |

### Cas d'usage Mistral AI

‚úÖ **Utilisez Mistral pour :**
- G√©n√©ration de playbooks Ansible
- Audit de s√©curit√© DevOps
- Documentation technique
- Analyse de configurations
- Usage quotidien en production

‚ùå **OpenAI peut √™tre pr√©f√©rable pour :**
- Traductions complexes multilingues
- G√©n√©ration de contenu marketing cr√©atif
- Cas d'usage tr√®s sp√©cialis√©s

---

## ‚ö° Configuration rapide (3 √©tapes)

### √âtape 1 : Obtenir votre cl√© API Mistral

1. Cr√©ez un compte sur [console.mistral.ai](https://console.mistral.ai/)
2. Allez dans **API Keys**
3. Cliquez sur **Create new key**
4. Donnez un nom : `CortexOps Production`
5. Copiez la cl√© (format : `xxx...`)

### √âtape 2 : Configurer la cl√© Mistral

Modifiez votre fichier `.env` :

```bash
# ‚úÖ REQUIS - Mistral AI (Provider principal)
VITE_MISTRAL_API_KEY=votre_cle_mistral_ici

# ‚ùå OPTIONNEL - OpenAI (D√©sactiv√©)
# VITE_OPENAI_API_KEY=

# Pour Ollama local (optionnel)
VITE_OLLAMA_ENDPOINT=http://localhost:11434
```

### √âtape 3 : Red√©marrer l'application

```bash
npm run dev
```

‚úÖ **C'est fait !** Mistral est maintenant le provider par d√©faut.

---

## üö´ D√©sactiver compl√®tement OpenAI

### Option 1 : Via l'interface (Recommand√©)

1. Allez dans **Param√®tres** ‚Üí **Providers AI**
2. Trouvez la section **OpenAI**
3. D√©sactivez le toggle
4. Cliquez sur **Enregistrer**

### Option 2 : Via le fichier .env

Commentez ou supprimez la ligne OpenAI :

```bash
# D√©sactiver OpenAI
# VITE_OPENAI_API_KEY=sk-xxxxxxxxxxxxx
```

### Option 3 : Suppression compl√®te (Avanc√©)

Si vous voulez supprimer compl√®tement le code OpenAI :

#### 1. Modifier `src/lib/aiModelConfig.ts`

Supprimez les mod√®les OpenAI :

```typescript
export const AI_MODELS = {
  // Mistral Models (Garder)
  'mistral-large': { ... },
  'mistral-small': { ... },
  'mistral-nemo': { ... },

  // OpenAI Models (Supprimer ces lignes)
  // 'gpt-4': { ... },
  // 'gpt-3.5-turbo': { ... },

  // Ollama (Garder)
  'ollama-mistral': { ... }
};
```

#### 2. Modifier `src/lib/aiService.ts`

Supprimez la m√©thode `generateOpenAI` :

```typescript
// Supprimer cette m√©thode compl√®te
/*
private async generateOpenAI(
  request: AIGenerationRequest,
  modelConfig: any
): Promise<AIGenerationResponse> {
  // ... supprimer tout le code
}
*/
```

Modifiez la m√©thode `generate` :

```typescript
async generate(request: AIGenerationRequest): Promise<AIGenerationResponse> {
  const modelConfig = getModelConfig(request.modelKey);

  switch (modelConfig.provider) {
    case 'mistral':
      return await this.generateMistral(request, modelConfig);

    // Supprimer ce case
    // case 'openai':
    //   return await this.generateOpenAI(request, modelConfig);

    case 'ollama':
      return await this.generateOllama(request, modelConfig);

    default:
      throw new Error(`Provider non support√©: ${modelConfig.provider}`);
  }
}
```

#### 3. Nettoyer le constructeur

```typescript
export class AIService {
  // Supprimer openaiKey
  private mistralKey?: string;

  constructor(mistralKey?: string) {
    this.mistralKey = mistralKey;
  }
}

// Modifier createAIService
export const createAIService = () => {
  const mistralKey = import.meta.env.VITE_MISTRAL_API_KEY;
  return new AIService(mistralKey);
};
```

#### 4. Mettre √† jour les tests de connexion

```typescript
async testConnection(provider: 'mistral' | 'ollama'): Promise<boolean> {
  try {
    switch (provider) {
      case 'mistral':
        if (!this.mistralKey) return false;
        const mistralRes = await fetch('https://api.mistral.ai/v1/models', {
          headers: { 'Authorization': `Bearer ${this.mistralKey}` }
        });
        return mistralRes.ok;

      // Supprimer le case openai

      case 'ollama':
        const ollamaRes = await fetch('http://localhost:11434/api/tags');
        return ollamaRes.ok;

      default:
        return false;
    }
  } catch {
    return false;
  }
}
```

#### 5. Rebuild l'application

```bash
npm run build
```

---

## ‚úÖ V√©rification et tests

### 1. V√©rifier la configuration

```bash
# Afficher les variables d'environnement
echo $VITE_MISTRAL_API_KEY  # Doit afficher votre cl√©
echo $VITE_OPENAI_API_KEY   # Doit √™tre vide
```

### 2. Tester dans l'interface

1. Ouvrez CortexOps
2. Allez dans **G√©n√©rateur de Playbooks**
3. Cliquez sur **S√©lecteur de mod√®le**
4. V√©rifiez que seuls les mod√®les Mistral sont disponibles
5. G√©n√©rez un playbook de test
6. V√©rifiez qu'il est g√©n√©r√© avec Mistral

### 3. Tester avec un playbook simple

```yaml
# Prompt de test
Cr√©er un playbook pour installer Nginx sur Ubuntu
```

Si la g√©n√©ration fonctionne, Mistral est bien configur√© !

### 4. V√©rifier les logs

Ouvrez la console du navigateur (F12) et cherchez :

```
‚úÖ Connexion Mistral AI : OK
‚ùå Connexion OpenAI : D√©sactiv√©e
```

---

## üí∞ Comparaison des co√ªts

### Exemple : G√©n√©rer 100 playbooks par jour

| Mod√®le | Tokens/playbook | Co√ªt/playbook | Co√ªt mensuel (3000 playbooks) |
|--------|----------------|---------------|------------------------------|
| **Mistral Small** | 1000 | 0,0002‚Ç¨ | 0,60‚Ç¨ |
| **Mistral Nemo** | 1000 | 0,00015‚Ç¨ | 0,45‚Ç¨ |
| **GPT-3.5 Turbo** | 1000 | 0,0005‚Ç¨ | 1,50‚Ç¨ |
| **GPT-4** | 1000 | 0,03‚Ç¨ | 90‚Ç¨ |

### √âconomies annuelles

- **Mistral Small vs GPT-3.5** : ~11‚Ç¨/an
- **Mistral Small vs GPT-4** : ~1 074‚Ç¨/an
- **Mistral Nemo vs GPT-4** : ~1 076‚Ç¨/an

---

## üîÑ Retour en arri√®re

Si vous souhaitez r√©activer OpenAI :

### 1. R√©activer dans .env

```bash
# D√©commenter la ligne
VITE_OPENAI_API_KEY=sk-votre_cle_openai
```

### 2. R√©activer dans l'interface

1. Allez dans **Param√®tres** ‚Üí **Providers AI**
2. Section **OpenAI**
3. Activez le toggle
4. Testez la connexion

### 3. Red√©marrer

```bash
npm run dev
```

---

## üìä Configuration Multi-Provider (Fallback)

Pour une haute disponibilit√©, configurez plusieurs providers :

```bash
# .env - Configuration recommand√©e
VITE_MISTRAL_API_KEY=xxx    # Provider principal
VITE_OPENAI_API_KEY=yyy     # Fallback 1
VITE_OLLAMA_ENDPOINT=zzz    # Fallback 2 (offline)
```

### Ordre de priorit√© automatique

1. **Mistral AI** (si disponible)
2. **OpenAI** (si Mistral √©choue)
3. **Ollama** (si tous √©chouent)

---

## üõ†Ô∏è Configuration avanc√©e

### Mod√®le par d√©faut

Modifiez `src/lib/aiModelConfig.ts` :

```typescript
export const DEFAULT_MODEL = 'mistral-small'; // Au lieu de 'gpt-3.5-turbo'
```

### D√©sactiver le s√©lecteur OpenAI

Dans `src/components/AIModelSelector.tsx` :

```typescript
const groupedModels = {
  'mistral': Object.entries(AI_MODELS).filter(([_, m]) => m.provider === 'mistral'),
  // 'openai': Object.entries(AI_MODELS).filter(([_, m]) => m.provider === 'openai'), // Comment√©
  'ollama': Object.entries(AI_MODELS).filter(([_, m]) => m.provider === 'ollama')
};
```

---

## ‚ùì FAQ

### Q : Puis-je utiliser les deux en m√™me temps ?

**R :** Oui ! Configurez les deux cl√©s et choisissez le mod√®le dans l'interface.

### Q : Mistral est-il aussi performant qu'OpenAI ?

**R :** Pour les playbooks Ansible et l'audit DevOps, Mistral est aussi performant, voire meilleur dans certains cas, √† un co√ªt 10x inf√©rieur.

### Q : Mes donn√©es sont-elles s√©curis√©es avec Mistral ?

**R :** Oui, Mistral respecte le RGPD et stocke les donn√©es en Europe (France), contrairement √† OpenAI qui est soumis au Cloud Act am√©ricain.

### Q : Comment savoir quel provider est utilis√© ?

**R :** L'interface affiche toujours le mod√®le utilis√© lors de la g√©n√©ration. Vous pouvez aussi v√©rifier dans les logs.

### Q : Que se passe-t-il si Mistral est indisponible ?

**R :** Si OpenAI est configur√©, il sera utilis√© automatiquement en fallback. Sinon, vous verrez une erreur.

### Q : Comment optimiser les co√ªts ?

**R :**
1. Utilisez `mistral-nemo` pour les t√¢ches simples
2. Utilisez `mistral-small` pour l'audit
3. R√©servez `mistral-large` pour les playbooks complexes

---

## üîó Liens utiles

- **Console Mistral AI** : https://console.mistral.ai/
- **Documentation Mistral** : https://docs.mistral.ai/
- **Tarifs Mistral** : https://mistral.ai/technology/#pricing
- **Comparaison des mod√®les** : Voir `AI_MODEL_DECISION_TREE.md`
- **Guide d'int√©gration complet** : Voir `MISTRAL_INTEGRATION.md`

---

## üìù Checklist de migration

Avant de passer √† Mistral exclusivement :

- [ ] J'ai cr√©√© un compte Mistral AI
- [ ] J'ai obtenu ma cl√© API
- [ ] J'ai configur√© VITE_MISTRAL_API_KEY dans .env
- [ ] J'ai d√©sactiv√© ou supprim√© VITE_OPENAI_API_KEY
- [ ] J'ai red√©marr√© l'application
- [ ] J'ai test√© la g√©n√©ration d'un playbook
- [ ] La g√©n√©ration fonctionne correctement
- [ ] J'ai v√©rifi√© les logs (aucune erreur)
- [ ] J'ai document√© ma configuration

---

## üéØ R√©sum√©

**En 3 lignes :**

1. Obtenez votre cl√© Mistral sur [console.mistral.ai](https://console.mistral.ai/)
2. Ajoutez `VITE_MISTRAL_API_KEY=xxx` dans `.env`
3. Commentez `VITE_OPENAI_API_KEY` pour d√©sactiver OpenAI

**B√©n√©fices :**
- ‚úÖ Co√ªts divis√©s par 10
- ‚úÖ Latence r√©duite de 50%
- ‚úÖ Conformit√© RGPD europ√©enne
- ‚úÖ M√™me qualit√© pour DevOps

**Inconv√©nients :**
- ‚ö†Ô∏è Moins de cas d'usage non-DevOps document√©s
- ‚ö†Ô∏è Communaut√© plus petite qu'OpenAI

---

**Bon migration ! üöÄ**

Pour toute question, consultez `MISTRAL_QUICK_START.md` ou `MISTRAL_INTEGRATION.md`.
